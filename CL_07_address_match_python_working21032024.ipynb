{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c500459-056e-402d-a9b8-118a319c50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Script to take planning applications and match to OSAddressBase addresses\n",
    "\n",
    "Written by: Christine Langston, March 2024\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b509a4-72c7-4f63-b2bb-0c53bcbe6e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a function to iterate through csv. use for OSAddressBase file\n",
    "def read_csv(file_name, columns):\n",
    "    for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns, \n",
    "                            dtype={'urpn':str, 'parent_urpn': str, 'class': str, 'latitude': float, \n",
    "                                                  'longitude': float, 'country': str}):\n",
    "    \n",
    "        #if chunk['country'] == 'E':\n",
    "        yield chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28e6b8f-8758-4551-9d3b-d271bd6dcb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#takes a merged dataset and separates matched addresses and not matched\n",
    "def separate_matches(dataset, column_name, match_strategy):\n",
    "    dataset_match = dataset.drop(dataset[pd.isna(dataset[column_name]) == True].index)\n",
    "    dataset_no_match = dataset.drop(dataset[pd.isna(dataset[column_name]) == False].index)\n",
    "    dataset_match['match_strategy'] = match_strategy\n",
    "    return dataset_match, dataset_no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d8c1aa-27ee-4fd2-a82d-8cca7c6d36b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to merge and then split based on if an address was matched  \n",
    "def my_merge(left, right, left_on, right_on): \n",
    "    merged = left.merge(right, how = 'left', left_on = left_on, right_on = right_on)\n",
    "    merged_match = merged.drop(merged[pd.isna(merged['uprn']) == True].index) \n",
    "    merged_no_match = merged.drop(merged[pd.isna(merged['uprn']) == False].index) \n",
    "    return merged_match, merged_no_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc08158-0950-4fee-953e-b90039e59f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\"\"\"\n",
    "fewer_columns  = ['uprn', 'parent_uprn', 'class', 'latitude', 'longitude', 'country' ]\n",
    "all_columns = ['uprn', 'parent_uprn', 'class', 'latitude', 'longitude', 'country', 'legal_name','sub_building_name',\n",
    "           'building_name','building_number','sao_start_number','sao_start_suffix','sao_end_number',\n",
    "           'sao_end_suffix','sao_text','alt_language_sao_text','pao_start_number','pao_start_suffix',\n",
    "           'pao_end_number','pao_end_suffix','pao_text','alt_language_pao_text','usrn','usrn_match_indicator',\n",
    "           'area_name','level','official_flag','os_address_toid','os_address_toid_version','os_roadlink_toid',\n",
    "           'os_roadlink_toid_version','os_topo_toid','os_topo_toid_version','voa_ct_record','voa_ndr_record',\n",
    "           'street_description','alt_language_street_description','dependent_thoroughfare','thoroughfare',\n",
    "           'double_dependent_locality','dependent_locality','locality', 'town_name', \n",
    "          'administrative_area','post_town','postcode','postcode_locator' ]\n",
    "\"\"\"\n",
    "\n",
    "address_matching_columns = ['uprn', 'parent_uprn', 'class', 'latitude', 'longitude', 'country',\n",
    "                    'legal_name','sub_building_name', 'building_name','building_number','street_description',\n",
    "                    'dependent_locality','locality', 'town_name', 'administrative_area','post_town','postcode' ]\n",
    "\n",
    "address_base_file = \"/Users/christine/Documents/_UCL_grad school/research/ab_plus_england_202308150944.csv\"\n",
    "\n",
    "nana_process_file = \"/Users/christine/OneDrive - University College London/WP1_Address list compilation/13_stage_3_from_NanaWei/PA_batch1_London_202402_processed.csv\"\n",
    "\n",
    "process_file_ben_columns = '/Users/christine/OneDrive - University College London/WP1_Address list compilation/13_stage_3_from_NanaWei/PA_batch1 with units and type_03192024.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b9964a-56ff-405a-bd75-06ad82a4f92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#london_file = \"/Users/christine/OneDrive - University College London/Attachments/PDdata_barch1_London_filtered.csv\"\n",
    "london_data = pd.read_csv(process_file_ben_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f65160-cd66-44ca-8666-57418764eb18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UCL_ID                         1338\n",
       "planning_application_number    1338\n",
       "lpa_name                       1338\n",
       "application_type               1338\n",
       "application_type_full           787\n",
       "description                    1310\n",
       "number_of_units                 856\n",
       "site_number_clean              1258\n",
       "street_name                     958\n",
       "postcode_clean                 1257\n",
       "ward                           1239\n",
       "site_name_clean                 213\n",
       "site_name_GLA                   817\n",
       "site_name_LPA                    41\n",
       "uprn                           1063\n",
       "decision                       1307\n",
       "status                         1155\n",
       "application_date                 40\n",
       "decision_date                     4\n",
       "PD_type                        1338\n",
       "Number_units_found                0\n",
       "FPP_PA_mix?                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### DATA EXPLORATION - SKIP IF JUST MATCHING \n",
    "#there are 1338 addresses in the London file, 1063 have a URPN, 275 do not have UPRN\n",
    "#1338 unique properties, 907 unique uprn\n",
    "london_data['UCL_ID'].nunique()\n",
    "london_data['uprn'].nunique()\n",
    "london_data.shape\n",
    "london_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1124a7f-1f93-4907-a21a-d9c160ff9824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### DATA EXPLORATION - SKIP IF JUST MATCHING \n",
    "#how many rows without uprns have an address? \n",
    "#london_data_no_uprn = london_data.dropna(subset=[\"uprn\n",
    "london_data_no_uprn = london_data.drop(london_data[pd.isna(london_data['uprn'])==False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2187d93-6f1a-4066-9ec2-f0bbebf2bb50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_98485/257141313.py:3: DtypeWarning: Columns (21,22,56,62,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_name, chunksize=10000, usecols=columns,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds:  273.93617701530457\n"
     ]
    }
   ],
   "source": [
    "#read in the address base data - 32 Million rows\n",
    "t = time.time()\n",
    "df_lst = [] \n",
    "\n",
    "\n",
    "# Iterate over the file based on the criteria and append to the list\n",
    "for df in read_csv(address_base_file, address_matching_columns):\n",
    "       # if df['country'] == 'E':\n",
    "       # tmp_df = (df.pipe(lambda x:  x[x.country == 'E'] ))\n",
    "    df_lst +=   [df.copy()] \n",
    "\n",
    "# And finally combine filtered df_lst into the final larger output say 'df_final' dataframe \n",
    "df_final = pd.concat(df_lst)\n",
    "print('seconds: ', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3076b9-5155-4cd9-977d-c3b351496c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "#edit the parent uprn from OSAddress base to fill out to be strings with 12 digits and leading zeros\n",
    "#replace nan\n",
    "df_final = df_final.replace([np.nan, -np.inf], 0)\n",
    "\n",
    "#cast as integer\n",
    "df_final['parent_uprn'] = df_final['parent_uprn'].astype('Int64')\n",
    "df_final['uprn'] = df_final['uprn'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0016326f-51fd-43ab-b3ff-2b4a02a5ddb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "#cast as string \n",
    "df_final['parent_uprn'] = df_final['parent_uprn'].astype(str)\n",
    "df_final['uprn'] = df_final['uprn'].astype(str)\n",
    "\n",
    "#fill in with left side padding zeros \n",
    "df_final['parent_uprn'] = df_final['parent_uprn'].apply(lambda x: '{0:0>12}'.format(x))\n",
    "df_final['uprn'] = df_final['uprn'].apply(lambda x: '{0:0>12}'.format(x))\n",
    "\n",
    "#print(df_final['parent_uprn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74acf72f-612b-40cf-b6e9-353b7ca0f843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "\n",
    "#london_data has extra quotation marks, need to remove\n",
    "london_data['uprn'] = london_data['uprn'].apply(lambda x: x.strip(\"''\") if not pd.isna(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b72a94-714d-4bc2-993f-a4342aae1f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "london_data['uprn'] = london_data['uprn'].astype('Int64')\n",
    "\n",
    "#cast the strings and make sure it looks good \n",
    "london_data['uprn'] = london_data['uprn'].astype('str') #apply(lambda x: str(x) if not pd.isna(x) else x)\n",
    "\n",
    "london_data['uprn'] = london_data['uprn'].apply(lambda x: '{0:0>12}'.format(x) if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e268f803-43d6-422d-a8d3-ea16f976ea71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "\n",
    "london_data = london_data.replace('00000000<NA>',np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5185cbad-13b5-4e16-a5f6-12c349dd89b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "#street address from site_name_LPA\n",
    "london_data['parsed_street_LPA'] = london_data['site_name_LPA'].apply(lambda x: re.findall(\"[0-9]+.-?.[0-9]+?\\s(.+)(Road|Lane|Avenue|Parade|Courtyard|Street|Gardens|Drive)\", x) if not pd.isna(x) and '-' in x\n",
    "                                                                  else (re.findall(\"[0-9]+\\s(.+)(Road|Lane|Avenue|Parade|Courtyard|Street|Gardens|Drive)\", x) if not pd.isna(x) else []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e31741b8-ad97-4ccc-96cc-5d2aecbc258f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "london_data['parsed_street_LPA'] =  london_data['parsed_street_LPA'].apply(lambda x: x[0][0] + x[0][1]  if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d0e2c6-a74a-4399-92d9-813f97ca4407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cleaning - street address\n",
    "london_data['parsed_street_GLA'] = london_data['site_name_GLA'].apply(lambda x: re.findall(\"[0-9]+.-?.[0-9]+?\\s(.+)(Road|Lane|Avenue|Parade|Courtyard|Street|Gardens|Drive)\", x) if not pd.isna(x) and '-' in x\n",
    "                                                                  else (re.findall(\"[0-9]+\\s(.+)(Road|Lane|Avenue|Parade|Courtyard|Street|Gardens|Drive)\", x) if not pd.isna(x) else []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c78b6f-f3e5-4d06-92a3-fcdcbde921a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "london_data['parsed_street_GLA'] =  london_data['parsed_street_GLA'].apply(lambda x: x[0][0] + x[0][1]  if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b23647b7-1efc-47b6-b392-71e3a42c3410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if the original street was empty, then we want to use the LPA Or GLA parsed name as street_name \n",
    "\n",
    "london_data['street_name'] = np.where(london_data['street_name'].isnull(), np.where(london_data['parsed_street_LPA'].isnull(), london_data['parsed_street_GLA'], london_data['parsed_street_LPA']), london_data['street_name'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a906a66-4f92-476f-bc42-6cc6f04f5060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DATA EXPLORATION - EXPORT CSV IF NEEDED \n",
    "#london_data.to_csv('london_data_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2889e1ef-cc0a-4561-9bb8-bf522d5798a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ DATA CLEANING  ----------\n",
    "\n",
    "#Address matching data clean, make building number into a string \n",
    "df_final['building_number'] = df_final['building_number'].astype('Int64').astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "070116ff-f50f-40ef-91f3-9bbb3bcff401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split the AddressBase into Residential uses and all others\n",
    "# 26,492,127 data ponits\n",
    "resi_AB = df_final[df_final['class'].str.startswith('R')] \n",
    "other_AB = df_final[df_final['class'].str.startswith('R') == False] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "165b7859-ce81-4d40-ab87-e19f63f395f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### -------- DATA MERGING --------\n",
    "#join the london data with the RESIDENTIAL AddressBase dataset on UPRN\n",
    "merged = london_data.merge(resi_AB, how = 'left', left_on = 'uprn', right_on = 'parent_uprn')\n",
    "\n",
    "#merged['UCL_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20c4535f-d653-4014-aa0a-594d74d508bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#separate merged into no match and match \n",
    "merged_match, merged_no_match = separate_matches(merged, 'parent_uprn', 'parent_uprn')\n",
    "\n",
    "merged_no_match = merged_no_match.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bc94052-a4b0-4f8b-ab48-962d4b59a966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge 2 on uprn not parent_uprn \n",
    "merged_2 = merged_no_match.merge(resi_AB, how = 'left', left_on = 'uprn_x', right_on = 'uprn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "040b81bd-843c-4d4d-b4f3-262ac6ea6297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#separate the merge 2 into two datasets for match v not match \n",
    "merged_2_match, merged_2_no_match = separate_matches(merged_2, 'uprn', 'uprn')\n",
    "\n",
    "merged_2_no_match = merged_2_no_match.dropna(axis=1, how='all')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab0f9b30-ea0f-4385-b318-b411f7cd0a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_2_match = merged_2_match.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "merged_match = merged_match.rename(columns={\"uprn_y\": \"uprn_OSAB\"})\n",
    "\n",
    "#merged_2_match.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc90bc5-3f98-4673-bb39-ecf74d8e7079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_matched = pd.concat([merged_2_match, merged_match])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0f39357-fdb8-474b-bb23-de10501ca4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-------- DATA MERGING -------- \n",
    "## ADDRESS STRATEGY ONE \n",
    "#match on the street number, street name, postcode \n",
    "left_columns = ['site_number_clean', 'street_name', 'postcode_clean']\n",
    "right_columns = ['building_number', 'street_description', 'postcode']\n",
    "\n",
    "# this is a very strict conservative join \n",
    "merged_on_address = merged_2_no_match.merge(resi_AB, how = 'left', left_on = left_columns, right_on = right_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11092479-5f92-497f-8b80-9567008c12f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_address_match,merged_on_address_no_match =  separate_matches(merged_on_address, 'uprn', 'address_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62afc2f3-632b-4e8a-95bf-988c18846964",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the merged_on_address_match to the matched\n",
    "merged_on_address_match = merged_on_address_match.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "#merged_on_address_match['match_strategy'] = 'address_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5933941c-2fdc-4a23-99d4-3c00d15ebb51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_matched = pd.concat([all_matched, merged_on_address_match])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e6e00d0-5edf-4645-834a-d41d5dbd8e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we would want to create a new column on this dataset that cleans up the site name\n",
    "merged_on_address_no_match['short_site_name_LPA]' ] = np.where(merged_on_address_no_match['site_name_LPA'].isnull() == False ,\n",
    "                                                        merged_on_address_no_match['site_name_LPA'].apply(lambda x: x.split(',')[0] if not pd.isna(x) else x ).str.lower(), \n",
    "                                                        merged_on_address_no_match['site_name_GLA'].apply(lambda x: x.split('\\r\\r\\n')[0] if not pd.isna(x) else x ).str.lower()  )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee8c1d6c-3f9e-4cd8-9411-e48403269a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_address_no_match = merged_on_address_no_match.dropna(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc1fab6b-4e53-4709-b668-fe9bc84ba9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_89449/2141146462.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resi_AB['number_street'] = np.where(resi_AB['building_name'] != 0,  resi_AB['building_name'].apply(lambda x: re.sub('[A-Z]', '',x) if type(x) == str else x)\n"
     ]
    }
   ],
   "source": [
    "##-------- DATA MERGING --------  STRATEGY 2 ADDRESS MATCH\n",
    "# concat AB Building number + AB street description = site_name_LPA before comma\n",
    "    #  and postcode  = postcode \n",
    "#create new column and oncatenate the buildign number and street\n",
    "\n",
    "resi_AB['number_street'] = np.where(resi_AB['building_name'] != 0,  resi_AB['building_name'].apply(lambda x: re.sub('[A-Z]', '',x) if type(x) == str else x)\n",
    ", resi_AB['building_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a823c5f2-c8b4-4dea-b08f-3676a8ec5ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_89449/2416929871.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  resi_AB['number_street'] =  resi_AB['number_street'] + ' ' + resi_AB['street_description'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "resi_AB['number_street'] =  resi_AB['number_street'] + ' ' + resi_AB['street_description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e800933c-6c15-4721-a906-9b3be0082eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "left_columns_2 = ['short_site_name_LPA]', 'postcode_clean'] \n",
    "right_columns_2 = ['number_street', 'postcode']\n",
    "\n",
    "merged_on_address2 = merged_on_address_no_match.merge(resi_AB, how = 'left', left_on = left_columns_2, right_on = right_columns_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8582e5bb-4f88-4289-9a13-e98f311f787e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_address2_match = merged_on_address2.drop(merged_on_address2[pd.isna(merged_on_address2['uprn']) == True].index) \n",
    "merged_on_address2_no_match = merged_on_address2.drop(merged_on_address2[pd.isna(merged_on_address2['uprn']) == False].index) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecde76ef-a35b-4da0-baea-a37a0f3cbc3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_address2_match = merged_on_address2_match.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "merged_on_address2_match = merged_on_address2_match.drop(columns = ['short_site_name_LPA]']) \n",
    "merged_on_address2_match['match_strategy'] = 'address_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e1b91f2-a0d2-4006-94b4-676678c0df9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_matched = pd.concat([all_matched, merged_on_address2_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77c5d607-7552-4d46-98cd-9bcc6d4af088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_address2_no_match = merged_on_address2_no_match.dropna(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4984641-af06-44eb-a845-880f0cf64da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_89449/3622273721.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_on_address2_no_match['lpa_name'] = merged_on_address2_no_match['lpa_name'].str.upper()\n"
     ]
    }
   ],
   "source": [
    "# #-------- DATA MERGING --------  STRATEGY 3 ADDRESS MATCH \n",
    "# concat AB Building number + AB street description = site_name_LPA before comma\n",
    "    # And AB administrative_area = LPA_name\n",
    "left_columns_3 = ['short_site_name_LPA]', 'lpa_name'] \n",
    "right_columns_3 = ['number_street', 'administrative_area']\n",
    "\n",
    "merged_on_address2_no_match['lpa_name'] = merged_on_address2_no_match['lpa_name'].str.upper()\n",
    "#merged_on_address3 = merged_on_address2_no_match.merge(resi_AB, how = 'left', left_on = left_columns_3, right_on = right_columns_3)\n",
    "\n",
    "merged_on_address3_match, merged_on_address3_no_match = my_merge(merged_on_address2_no_match, resi_AB, left_columns_3, right_columns_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c79f0700-afc0-44fa-bd75-43a0e982fc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the matched into all matched\n",
    "merged_on_address3_match = merged_on_address3_match.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "merged_on_address3_match = merged_on_address3_match.drop(columns = ['short_site_name_LPA]']) \n",
    "merged_on_address3_match['match_strategy'] = 'address_3'\n",
    "\n",
    "frames = [all_matched, merged_on_address3_match]\n",
    "\n",
    "all_matched = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebced5a5-32c2-433e-b196-83af5919bdb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_on_address3_no_match = merged_on_address3_no_match.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e43cee96-8012-4f44-9a22-18b3218516de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#columns_to_drop = ['legal_name','sub_building_name','building_name','building_number','street_description','dependent_locality','locality','town_name','administrative_area','post_town','postcode','uprn','class','parent_uprn','latitude','longitude','country', 'number_street_y']\n",
    "#merged_on_address3_no_match = merged_on_address3_no_match.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3b7af-a757-4c58-bce1-26fe30a1444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  STRATEGY 4 ADDRESS MATCH \n",
    "#match based on address number and postcode\n",
    "#left_columns_4 = ['site_number_clean', 'postcode_clean']\n",
    "#right_columns_4 = ['building_number', 'postcode']\n",
    "\n",
    "# this is a loose join \n",
    "#merged_on_address4 = merged_on_address3_no_match.merge(resi_AB, how = 'left', left_on = left_columns_4, right_on = right_columns_4)\n",
    "\n",
    "#other ideas: \n",
    "# if site name starts with a non number, remove the first comma and try strat 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ad5eb21-c0fa-4612-bccd-31f77313e25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##-------- DATA MERGING --------  COMMERCIAL PROPERTIES --- Reproduce the process with commercial properties \n",
    "#Merge on Parent UPRN \n",
    "non_resi_merged = merged_on_address3_no_match.merge(other_AB,how = 'left', left_on = 'uprn_x', right_on = 'parent_uprn')\n",
    "\n",
    "non_resi_match, non_resi_no_match =  separate_matches(non_resi_merged, 'parent_uprn', 'parent_uprn')\n",
    "\n",
    "non_resi_no_match = non_resi_no_match.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d6e60bd-519d-4476-b702-fcff09d5894e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge on UPRN\n",
    "non_resi_merged_2 = non_resi_no_match.merge(other_AB, how = 'left', left_on = 'uprn_x', right_on = 'uprn')\n",
    "\n",
    "non_resi_match_2, non_resi_no_match_2 =  separate_matches(non_resi_merged_2, 'parent_uprn', 'uprn')\n",
    "\n",
    "non_resi_no_match_2 = non_resi_no_match_2.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35233bd0-1e5b-476b-a4e1-784aa153f75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_resi_match_2 = non_resi_match_2.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "#non_resi_match_2['match_strategy'] = 'uprn'\n",
    "non_resi_match_2.count()\n",
    "\n",
    "non_resi_match = non_resi_match.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "#non_resi_match['match_strategy'] = 'parent_uprn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a766aec8-4f2a-4620-8938-c6a6c8df7c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#union them together \n",
    "non_resi_all_matched = pd.concat([non_resi_match_2, non_resi_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff3df69e-74fd-4280-a8c6-f6d498751b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now join on addresses strat 1 \n",
    "left_columns = ['site_number_clean', 'street_name', 'postcode_clean']\n",
    "right_columns = ['building_number', 'street_description', 'postcode']\n",
    "\n",
    "non_resi_address_merge_match, non_resi_address_merge_no_match = my_merge(non_resi_no_match_2, other_AB, left_columns, right_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89237c05-b592-4be1-ab3b-4c10a7045051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_resi_address_merge_no_match = non_resi_address_merge_no_match.dropna(axis=1, how='all')\n",
    "\n",
    "## Add the merged_on_address_match to the matched\n",
    "non_resi_address_merge_match = non_resi_address_merge_match.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "non_resi_address_merge_match['match_strategy'] = 'address_1'\n",
    "\n",
    "non_resi_all_matched = pd.concat([non_resi_all_matched, non_resi_address_merge_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5a5799b-2902-4c5f-aefd-3556ecf780d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_89449/3097699056.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_AB['number_street'] = np.where(other_AB['building_name'] != 0,  other_AB['building_name'].apply(lambda x: re.sub('[A-Z]', '',x) if type(x) == str else x)\n",
      "/var/folders/0b/k156jw2x3rz7y1k26v1wkh880000gn/T/ipykernel_89449/3097699056.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_AB['number_street'] =  other_AB['number_street'] + ' ' + other_AB['street_description'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "#join addresses strat 2\n",
    "#make change to the other_AB dataset \n",
    "other_AB['number_street'] = np.where(other_AB['building_name'] != 0,  other_AB['building_name'].apply(lambda x: re.sub('[A-Z]', '',x) if type(x) == str else x)\n",
    ", other_AB['building_number'])\n",
    "other_AB['number_street'] =  other_AB['number_street'] + ' ' + other_AB['street_description'].str.lower()\n",
    "\n",
    "\n",
    "left_columns_2 = ['short_site_name_LPA]', 'postcode_clean'] \n",
    "right_columns_2 = ['number_street', 'postcode']\n",
    " \n",
    "non_resi_address_merge_match2, non_resi_address_merge_no_match2 = my_merge(non_resi_address_merge_no_match, other_AB, left_columns_2,right_columns_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40e38bdf-0103-4cac-949a-cc02dbe53e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_resi_address_merge_no_match2 = non_resi_address_merge_no_match2.dropna(axis=1, how='all')\n",
    "\n",
    "## Add the merged_on_address_match to the matched\n",
    "non_resi_address_merge_match2 = non_resi_address_merge_match2.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "non_resi_address_merge_match2['match_strategy'] = 'address_2'\n",
    "\n",
    "non_resi_all_matched = pd.concat([non_resi_all_matched, non_resi_address_merge_match2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a746488-62e0-40f3-980e-d20722040d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STRATEGY 3 ADDRESS MATCH \n",
    "# concat AB Building number + AB street description = site_name_LPA before comma\n",
    "    # And AB administrative_area = LPA_name\n",
    "left_columns_3 = ['short_site_name_LPA]', 'lpa_name'] \n",
    "right_columns_3 = ['number_street', 'administrative_area']\n",
    "\n",
    "non_resi_address_merge_no_match2['lpa_name'] = non_resi_address_merge_no_match2['lpa_name'].str.upper()\n",
    "#merged_on_address3 = merged_on_address2_no_match.merge(resi_AB, how = 'left', left_on = left_columns_3, right_on = right_columns_3)\n",
    "\n",
    "non_resi_address_merge_match3, non_resi_address_merge_no_match3 = my_merge(non_resi_address_merge_no_match2, other_AB, left_columns_3, right_columns_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09850e80-0072-40cc-9acf-4b827b8e79f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_resi_address_merge_no_match3 = non_resi_address_merge_no_match3.dropna(axis=1, how='all')\n",
    "\n",
    "## Add the merged_on_address_match to the matched\n",
    "non_resi_address_merge_match3 = non_resi_address_merge_match3.rename(columns={\"uprn\": \"uprn_OSAB\"})\n",
    "non_resi_address_merge_match3['match_strategy'] = 'address_3'\n",
    "\n",
    "non_resi_all_matched = pd.concat([non_resi_all_matched, non_resi_address_merge_match3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83452072-fa8b-4bd9-8df8-712049bb007b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ------------------------------- Post Match  -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8eee3873-8729-4cfa-9ab6-17e877174e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resi Match rate:  33.78176382660688\n",
      "Other Match rate:  41.70403587443946\n"
     ]
    }
   ],
   "source": [
    "#print match rate\n",
    "resi_match_rate = 100 * all_matched['UCL_ID'].nunique() / london_data['UCL_ID'].nunique()\n",
    "\n",
    "print('Resi Match rate: ', resi_match_rate) \n",
    "\n",
    "other_match_rate = 100 * non_resi_all_matched['UCL_ID'].nunique() / london_data['UCL_ID'].nunique()\n",
    "\n",
    "print('Other Match rate: ', other_match_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8575f697-728d-480f-9520-5fb95ee038fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#before export, make all these columns blank instead of 0 \n",
    "#'legal_name', 'sub_building_name', 'building_name','building_number','street_description', 'dependent_locality\tlocality\n",
    "all_matched['street_name'] = all_matched['street_name'].replace(0,'')\n",
    "all_matched['legal_name'] = all_matched['legal_name'].replace(0,'')\n",
    "all_matched['sub_building_name'] = all_matched['sub_building_name'].replace(0,'')\n",
    "all_matched['building_name'] = all_matched['building_name'].replace(0,'')\n",
    "all_matched['building_number'] = all_matched['building_number'].replace(0,'')\n",
    "all_matched['street_description'] = all_matched['street_description'].replace(0,'')\n",
    "all_matched['dependent_locality'] = all_matched['dependent_locality'].replace(0,'')\n",
    "all_matched['locality'] = all_matched['locality'].replace(0,'')\n",
    "all_matched['post_town'] = all_matched['post_town'].replace(0,'')\n",
    "all_matched['postcode'] = np.where(all_matched['postcode'] == 0, all_matched['postcode_clean'], all_matched['postcode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b6ab65e-43b9-4bf8-bf42-a37c32744d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UCL_ID</th>\n",
       "      <th>planning_application_number</th>\n",
       "      <th>lpa_name</th>\n",
       "      <th>application_type</th>\n",
       "      <th>application_type_full</th>\n",
       "      <th>description</th>\n",
       "      <th>number_of_units</th>\n",
       "      <th>site_number_clean</th>\n",
       "      <th>street_name</th>\n",
       "      <th>postcode_clean</th>\n",
       "      <th>...</th>\n",
       "      <th>town_name</th>\n",
       "      <th>administrative_area</th>\n",
       "      <th>post_town</th>\n",
       "      <th>postcode</th>\n",
       "      <th>match_strategy</th>\n",
       "      <th>Number_units_found</th>\n",
       "      <th>FPP_PA_mix?</th>\n",
       "      <th>number_street</th>\n",
       "      <th>number_street_x</th>\n",
       "      <th>number_street_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>54</td>\n",
       "      <td>21/01316/PREZA</td>\n",
       "      <td>Newham</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>Prior Approval: Change of use - light industri...</td>\n",
       "      <td>Application to determine if prior approval is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2A</td>\n",
       "      <td>Boundary Road</td>\n",
       "      <td>E13 9PR</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>NEWHAM</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>E13 9PR</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>123</td>\n",
       "      <td>21/00771/PRECOU</td>\n",
       "      <td>Newham</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>Prior Approval: Change of use - retail/service...</td>\n",
       "      <td>Prior approval for the change of the retail un...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140</td>\n",
       "      <td>Portway</td>\n",
       "      <td>E15 3QW</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>NEWHAM</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>E15 3QW</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>132</td>\n",
       "      <td>19/AP/1141</td>\n",
       "      <td>Southwark</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>Prior Approval: Change of use - storage to dwe...</td>\n",
       "      <td>Notification for prior approval for a change o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4A</td>\n",
       "      <td>None</td>\n",
       "      <td>SE1 4QG</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>SOUTHWARK</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>SE1 4QG</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>142</td>\n",
       "      <td>22/02610/PRECOU</td>\n",
       "      <td>Newham</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>Prior Approval: Change of use from Commercial,...</td>\n",
       "      <td>Prior approval for the change of use of the ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>Portway</td>\n",
       "      <td>E15 3QW</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>NEWHAM</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>E15 3QW</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>145</td>\n",
       "      <td>22/AP/3633</td>\n",
       "      <td>Southwark</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>Prior Approval: Change of use from Commercial,...</td>\n",
       "      <td>Prior approval notification for the change of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>ONEGA GATE</td>\n",
       "      <td>SE16 7PF</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>SOUTHWARK</td>\n",
       "      <td></td>\n",
       "      <td>SE16 7PF</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>149</td>\n",
       "      <td>22/03970/PIAPA</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>Prior Approval: Change of use from Commercial,...</td>\n",
       "      <td>Application for Prior Approval Under Class G o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>Rochester Row</td>\n",
       "      <td>SW1P 1JU</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>CITY OF WESTMINSTER</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>SW1P 1JU</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>163</td>\n",
       "      <td>20/2001/PNO</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Change of use of ground and lower ground floor...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leicester Road</td>\n",
       "      <td>EN5 5EW</td>\n",
       "      <td>...</td>\n",
       "      <td>BARNET</td>\n",
       "      <td>BARNET</td>\n",
       "      <td>BARNET</td>\n",
       "      <td>EN5 5EW</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>167</td>\n",
       "      <td>22/1285/GPD26</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHANGE OF USE TO SINGLE DWELLING HOUSE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Bridle Lane</td>\n",
       "      <td>TW1 3EG</td>\n",
       "      <td>...</td>\n",
       "      <td>TWICKENHAM</td>\n",
       "      <td>RICHMOND UPON THAMES</td>\n",
       "      <td>TWICKENHAM</td>\n",
       "      <td>TW1 3EG</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>181</td>\n",
       "      <td>21/03383/PRIOR</td>\n",
       "      <td>Bexley</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notification for Prior Approval for change of ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Sidcup High Street</td>\n",
       "      <td>DA14 6EP</td>\n",
       "      <td>...</td>\n",
       "      <td>SIDCUP</td>\n",
       "      <td>BEXLEY</td>\n",
       "      <td>SIDCUP</td>\n",
       "      <td>DA14 6EP</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>185</td>\n",
       "      <td>DM2020/00970</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from an offic...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177</td>\n",
       "      <td>Gander Green Lane</td>\n",
       "      <td>SM1 2EZ</td>\n",
       "      <td>...</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SM1 2EZ</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>187</td>\n",
       "      <td>DM2019/00922</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from an offic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59A</td>\n",
       "      <td>None</td>\n",
       "      <td>SM6 8LA</td>\n",
       "      <td>...</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>SM6 8LA</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>188</td>\n",
       "      <td>DM2019/00420</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from an offic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>Westmead Road</td>\n",
       "      <td>SM1 4JD</td>\n",
       "      <td>...</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SM1 4JD</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>189</td>\n",
       "      <td>DM2019/00332</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from an offic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>Haddon Road</td>\n",
       "      <td>SM1 1RN</td>\n",
       "      <td>...</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SM1 1RN</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>192</td>\n",
       "      <td>DM2020/00536</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from an offic...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>164C</td>\n",
       "      <td>Stafford Road</td>\n",
       "      <td>SM6 9BS</td>\n",
       "      <td>...</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>SM6 9BS</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>196</td>\n",
       "      <td>DM2019/01612</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from an offic...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48</td>\n",
       "      <td>MANOR ROAD</td>\n",
       "      <td>SM6 0AB</td>\n",
       "      <td>...</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>WALLINGTON</td>\n",
       "      <td>SM6 0AB</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>201</td>\n",
       "      <td>DM2019/00419</td>\n",
       "      <td>Sutton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prior Approval for change of use from storage ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>Westmead Road</td>\n",
       "      <td>SM1 4JD</td>\n",
       "      <td>...</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>SM1 4JD</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>242</td>\n",
       "      <td>PA/21/00254/NC</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application for Prior Approval under Part 3 Cl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>Pepper Street</td>\n",
       "      <td>E14 9RP</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>TOWER HAMLETS</td>\n",
       "      <td></td>\n",
       "      <td>E14 9RP</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>243</td>\n",
       "      <td>PA/21/01176/A1</td>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application for Prior Approval under Part 3 Cl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>Pepper Street</td>\n",
       "      <td>E14 9RP</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>TOWER HAMLETS</td>\n",
       "      <td></td>\n",
       "      <td>E14 9RP</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>248</td>\n",
       "      <td>J0005.23</td>\n",
       "      <td>Havering</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Application for Prior Notification of Change o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>HAVERING</td>\n",
       "      <td>RM2 5UB</td>\n",
       "      <td>...</td>\n",
       "      <td>ROMFORD</td>\n",
       "      <td>HAVERING</td>\n",
       "      <td>ROMFORD</td>\n",
       "      <td>RM2 5UB</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>254</td>\n",
       "      <td>21/P1688</td>\n",
       "      <td>Merton</td>\n",
       "      <td>Prior Approval</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPLICATION TO DETERMINE IF PRIOR APPROVAL IS ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>Merton High Street</td>\n",
       "      <td>SW19 1BD</td>\n",
       "      <td>...</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>MERTON</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>SW19 1BD</td>\n",
       "      <td>uprn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UCL_ID planning_application_number       lpa_name application_type  \\\n",
       "42       54              21/01316/PREZA         Newham   Prior Approval   \n",
       "87      123             21/00771/PRECOU         Newham   Prior Approval   \n",
       "93      132                  19/AP/1141      Southwark   Prior Approval   \n",
       "99      142             22/02610/PRECOU         Newham   Prior Approval   \n",
       "102     145                  22/AP/3633      Southwark   Prior Approval   \n",
       "106     149              22/03970/PIAPA    Westminster   Prior Approval   \n",
       "115     163                 20/2001/PNO         Barnet   Prior Approval   \n",
       "118     167               22/1285/GPD26       Richmond   Prior Approval   \n",
       "130     181              21/03383/PRIOR         Bexley   Prior Approval   \n",
       "134     185                DM2020/00970         Sutton   Prior Approval   \n",
       "136     187                DM2019/00922         Sutton   Prior Approval   \n",
       "137     188                DM2019/00420         Sutton   Prior Approval   \n",
       "138     189                DM2019/00332         Sutton   Prior Approval   \n",
       "140     192                DM2020/00536         Sutton   Prior Approval   \n",
       "144     196                DM2019/01612         Sutton   Prior Approval   \n",
       "148     201                DM2019/00419         Sutton   Prior Approval   \n",
       "177     242              PA/21/00254/NC  Tower Hamlets   Prior Approval   \n",
       "178     243              PA/21/01176/A1  Tower Hamlets   Prior Approval   \n",
       "183     248                    J0005.23       Havering   Prior Approval   \n",
       "189     254                    21/P1688         Merton   Prior Approval   \n",
       "\n",
       "                                 application_type_full  \\\n",
       "42   Prior Approval: Change of use - light industri...   \n",
       "87   Prior Approval: Change of use - retail/service...   \n",
       "93   Prior Approval: Change of use - storage to dwe...   \n",
       "99   Prior Approval: Change of use from Commercial,...   \n",
       "102  Prior Approval: Change of use from Commercial,...   \n",
       "106  Prior Approval: Change of use from Commercial,...   \n",
       "115                                                NaN   \n",
       "118                                                NaN   \n",
       "130                                                NaN   \n",
       "134                                                NaN   \n",
       "136                                                NaN   \n",
       "137                                                NaN   \n",
       "138                                                NaN   \n",
       "140                                                NaN   \n",
       "144                                                NaN   \n",
       "148                                                NaN   \n",
       "177                                                NaN   \n",
       "178                                                NaN   \n",
       "183                                                NaN   \n",
       "189                                                NaN   \n",
       "\n",
       "                                           description  number_of_units  \\\n",
       "42   Application to determine if prior approval is ...              NaN   \n",
       "87   Prior approval for the change of the retail un...              3.0   \n",
       "93   Notification for prior approval for a change o...              4.0   \n",
       "99   Prior approval for the change of use of the ba...              NaN   \n",
       "102  Prior approval notification for the change of ...              NaN   \n",
       "106  Application for Prior Approval Under Class G o...              NaN   \n",
       "115  Change of use of ground and lower ground floor...              1.0   \n",
       "118             CHANGE OF USE TO SINGLE DWELLING HOUSE              1.0   \n",
       "130  Notification for Prior Approval for change of ...              1.0   \n",
       "134  Prior Approval for change of use from an offic...              1.0   \n",
       "136  Prior Approval for change of use from an offic...              NaN   \n",
       "137  Prior Approval for change of use from an offic...              NaN   \n",
       "138  Prior Approval for change of use from an offic...              NaN   \n",
       "140  Prior Approval for change of use from an offic...              2.0   \n",
       "144  Prior Approval for change of use from an offic...              5.0   \n",
       "148  Prior Approval for change of use from storage ...              NaN   \n",
       "177  Application for Prior Approval under Part 3 Cl...              NaN   \n",
       "178  Application for Prior Approval under Part 3 Cl...              NaN   \n",
       "183  Application for Prior Notification of Change o...              NaN   \n",
       "189  APPLICATION TO DETERMINE IF PRIOR APPROVAL IS ...              NaN   \n",
       "\n",
       "    site_number_clean         street_name postcode_clean  ...   town_name  \\\n",
       "42                 2A       Boundary Road        E13 9PR  ...      LONDON   \n",
       "87                140             Portway        E15 3QW  ...      LONDON   \n",
       "93                 4A                None        SE1 4QG  ...      LONDON   \n",
       "99                140             Portway        E15 3QW  ...      LONDON   \n",
       "102                 3          ONEGA GATE       SE16 7PF  ...      LONDON   \n",
       "106                54       Rochester Row       SW1P 1JU  ...      LONDON   \n",
       "115                 3      Leicester Road        EN5 5EW  ...      BARNET   \n",
       "118                 5         Bridle Lane        TW1 3EG  ...  TWICKENHAM   \n",
       "130                13  Sidcup High Street       DA14 6EP  ...      SIDCUP   \n",
       "134               177   Gander Green Lane        SM1 2EZ  ...      SUTTON   \n",
       "136               59A                None        SM6 8LA  ...  WALLINGTON   \n",
       "137               108       Westmead Road        SM1 4JD  ...      SUTTON   \n",
       "138                45         Haddon Road        SM1 1RN  ...      SUTTON   \n",
       "140              164C       Stafford Road        SM6 9BS  ...  WALLINGTON   \n",
       "144                48          MANOR ROAD        SM6 0AB  ...  WALLINGTON   \n",
       "148               108       Westmead Road        SM1 4JD  ...      SUTTON   \n",
       "177                19       Pepper Street        E14 9RP  ...      LONDON   \n",
       "178                19       Pepper Street        E14 9RP  ...      LONDON   \n",
       "183                27            HAVERING        RM2 5UB  ...     ROMFORD   \n",
       "189                94  Merton High Street       SW19 1BD  ...      LONDON   \n",
       "\n",
       "      administrative_area   post_town  postcode match_strategy  \\\n",
       "42                 NEWHAM      LONDON   E13 9PR           uprn   \n",
       "87                 NEWHAM      LONDON   E15 3QW           uprn   \n",
       "93              SOUTHWARK      LONDON   SE1 4QG           uprn   \n",
       "99                 NEWHAM      LONDON   E15 3QW           uprn   \n",
       "102             SOUTHWARK              SE16 7PF           uprn   \n",
       "106   CITY OF WESTMINSTER      LONDON  SW1P 1JU           uprn   \n",
       "115                BARNET      BARNET   EN5 5EW           uprn   \n",
       "118  RICHMOND UPON THAMES  TWICKENHAM   TW1 3EG           uprn   \n",
       "130                BEXLEY      SIDCUP  DA14 6EP           uprn   \n",
       "134                SUTTON      SUTTON   SM1 2EZ           uprn   \n",
       "136                SUTTON  WALLINGTON   SM6 8LA           uprn   \n",
       "137                SUTTON      SUTTON   SM1 4JD           uprn   \n",
       "138                SUTTON      SUTTON   SM1 1RN           uprn   \n",
       "140                SUTTON  WALLINGTON   SM6 9BS           uprn   \n",
       "144                SUTTON  WALLINGTON   SM6 0AB           uprn   \n",
       "148                SUTTON      SUTTON   SM1 4JD           uprn   \n",
       "177         TOWER HAMLETS               E14 9RP           uprn   \n",
       "178         TOWER HAMLETS               E14 9RP           uprn   \n",
       "183              HAVERING     ROMFORD   RM2 5UB           uprn   \n",
       "189                MERTON      LONDON  SW19 1BD           uprn   \n",
       "\n",
       "    Number_units_found FPP_PA_mix? number_street number_street_x  \\\n",
       "42                 NaN         NaN           NaN             NaN   \n",
       "87                 NaN         NaN           NaN             NaN   \n",
       "93                 NaN         NaN           NaN             NaN   \n",
       "99                 NaN         NaN           NaN             NaN   \n",
       "102                NaN         NaN           NaN             NaN   \n",
       "106                NaN         NaN           NaN             NaN   \n",
       "115                NaN         NaN           NaN             NaN   \n",
       "118                NaN         NaN           NaN             NaN   \n",
       "130                NaN         NaN           NaN             NaN   \n",
       "134                NaN         NaN           NaN             NaN   \n",
       "136                NaN         NaN           NaN             NaN   \n",
       "137                NaN         NaN           NaN             NaN   \n",
       "138                NaN         NaN           NaN             NaN   \n",
       "140                NaN         NaN           NaN             NaN   \n",
       "144                NaN         NaN           NaN             NaN   \n",
       "148                NaN         NaN           NaN             NaN   \n",
       "177                NaN         NaN           NaN             NaN   \n",
       "178                NaN         NaN           NaN             NaN   \n",
       "183                NaN         NaN           NaN             NaN   \n",
       "189                NaN         NaN           NaN             NaN   \n",
       "\n",
       "    number_street_y  \n",
       "42              NaN  \n",
       "87              NaN  \n",
       "93              NaN  \n",
       "99              NaN  \n",
       "102             NaN  \n",
       "106             NaN  \n",
       "115             NaN  \n",
       "118             NaN  \n",
       "130             NaN  \n",
       "134             NaN  \n",
       "136             NaN  \n",
       "137             NaN  \n",
       "138             NaN  \n",
       "140             NaN  \n",
       "144             NaN  \n",
       "148             NaN  \n",
       "177             NaN  \n",
       "178             NaN  \n",
       "183             NaN  \n",
       "189             NaN  \n",
       "\n",
       "[20 rows x 45 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matched.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f807ae3-2cb7-4d0c-a3b1-36f9fe6dd0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#write out to csv \n",
    "\n",
    "all_matched.to_csv('London1_address_matched_1903.csv', index=False) \n",
    "\n",
    "non_resi_all_matched.to_csv('London1_non_resi_match_1903.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c218041-111b-41bc-b6de-b82dbf94a23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_resi_address_merge_no_match3.to_csv('London1_no_match_1903.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47f9bf-3c17-4da3-b691-787e7395a13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sds2023",
   "language": "python",
   "name": "sds2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
